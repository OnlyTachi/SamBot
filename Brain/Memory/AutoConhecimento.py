import logging
import json
from Brain.Providers.LLMFactory import LLMFactory
from Brain.Tools.BuscaTools import BuscaTool
from Brain.Memory.DataManager import NeuralArchive

class AutoConhecimento:
    def __init__(self):
        self.logger = logging.getLogger("SamBot.AutoConhecimento")
        self.llm = LLMFactory.get_instance()
        self.busca_tool = BuscaTool()
        self.data_manager = NeuralArchive()

    def _get_identity_data(self):
        """
        Recupera os dados de identidade de forma segura via DataManager.
        """
        if hasattr(self.data_manager, "get_identity"):
            return self.data_manager.get_identity()
        data = self.data_manager._cache.get("identity")
        if not data:
             try:
                 path = self.data_manager.folders["persistence"] / "identity.json"
                 data = self.data_manager._io_read_json(path)
                 self.data_manager._cache["identity"] = data
             except Exception as e:
                 self.logger.error(f"Erro crÃ­tico ao ler identidade: {e}")
                 return {}
        return data

    def is_self_inquiry(self, text: str) -> bool:
        """Verifica se a pergunta Ã© sobre a identidade da bot."""
        gatilhos = ["quem Ã© vocÃª", "quem e voce", "te criou", "seu autor", "sua tecnologia", "como vocÃª funciona"]
        return any(g in text.lower() for g in gatilhos)

    def get_identity_prompt(self):
        """Retorna o prompt base de identidade para o Agent usar."""
        identity = self._get_identity_data()
        return (
            f"VocÃª Ã© a {identity.get('name', 'SamBot')}. "
            f"Sua descriÃ§Ã£o: {identity.get('description')}. "
            f"Responda de forma carismÃ¡tica baseando-se no seu JSON de identidade."
        )

    async def apresentar(self):
        """
        Gera uma apresentaÃ§Ã£o baseada exclusivamente no JSON de identidade.
        """
        identity = self._get_identity_data()
        nome = identity.get("name", "SamBot")
        desc = identity.get("description", "Sou uma bot em desenvolvimento.")
        
        intro = (
            f"OlÃ¡! Eu sou a **{nome}**. ğŸ¤–âœ¨\n"
            f"*{desc}*\n\n"
            "Sou um sistema complexo e modular. O que vocÃª gostaria de saber?\n"
            "ğŸ§  **Meu CÃ©rebro** (IA HÃ­brida)\n"
            "ğŸ’¾ **Minha MemÃ³ria** (ChromaDB)\n"
            "ğŸ”Š **Meus Ouvidos** (Lavalink)\n"
            "ğŸ”§ **Minhas Ferramentas** (Jogos, Imagens, Web...)\n\n"
            "*Experimente perguntar: 'Quem te criou?' ou 'Como vocÃª toca mÃºsica?'*"
        )
        return intro

    async def refletir_e_responder(self, pergunta: str):
        """
        Responde perguntas sobre si mesma usando o identity.json como base.
        Realiza pesquisa na web se houver comparaÃ§Ã£o tÃ©cnica.
        """
        pergunta = pergunta.lower()
        identity = self._get_identity_data()

        # 1. DetecÃ§Ã£o de IntenÃ§Ã£o de ComparaÃ§Ã£o (Gatilho para Pesquisa)
        gatilhos_pesquisa = ["melhor que", "por que usa", "pq usa", "diferenÃ§a entre", "ao invÃ©s de", "alternativa"]
        precisa_pesquisar = any(g in pergunta for g in gatilhos_pesquisa)

        contexto_pesquisa = ""
        if precisa_pesquisar:
            self.logger.info(f"AutoConhecimento: Pesquisando contexto para '{pergunta}'")
            # Pesquisa genÃ©rica sobre a stack da bot para dar contexto
            query = f"{pergunta} python discord bot technology comparison"
            resultados = self.busca_tool.buscar_na_cascata(query)
            contexto_pesquisa = f"\n[CONTEXTO DA WEB - USE PARA COMPARAR]:\n{resultados}\n"

        # 2. Montagem do Prompt com a Identidade DinÃ¢mica
        identity_str = json.dumps(identity, indent=2, ensure_ascii=False)
        # dia 132 tentando melhorar a clareza do prompt
        prompt_sistema = (
            f"VocÃª Ã© a {identity.get('name', 'SamBot')}. Responda Ã  pergunta do usuÃ¡rio sobre vocÃª.\n"
            "Seja carismÃ¡tica, use emojis moderados e fale na primeira pessoa.\n\n"
            "=== SUA IDENTIDADE (A ÃšNICA VERDADE) ===\n"
            f"{identity_str}\n"
            "========================================\n"
            f"{contexto_pesquisa}\n"
            "DIRETRIZES:\n"
            "- BASEIE-SE ESTRITAMENTE no JSON acima para dizer o que vocÃª Ã©/usa.\n"
            "- Se o JSON diz que vocÃª usa Lavalink, NÃƒO diga que usa ffmpeg puro.\n"
            "- Se o usuÃ¡rio perguntou 'Por que X?', use o CONTEXTO DA WEB para explicar as vantagens de X,\n"
            "  mas confirme que vocÃª usa X porque estÃ¡ na sua identidade.\n"
            "- Se perguntarem quem Ã© o criador, cite o campo 'author'."
        )

        # 3. GeraÃ§Ã£o da Resposta
        resposta = await self.llm.generate_response(prompt_sistema, pergunta)
        return resposta

    def get_resumo_cerebro(self):
        brain = self._get_identity_data().get("brain", {})
        return f"Meu cÃ©rebro Ã© **{brain.get('type', 'HÃ­brido')}**. Uso principalmente **{brain.get('layer_1')}** para pensar, mas tenho **{brain.get('layer_2')}** e memÃ³ria vetorial como backup!"

    def get_resumo_audio(self):
        arch = self._get_identity_data().get("architecture", {})
        return f"Para mÃºsica, eu uso o motor **{arch.get('audio_engine', 'Lavalink')}**. Isso garante Ã¡udio de alta qualidade sem travar meu pensamento."

AutoConhecimentoManager = AutoConhecimento()